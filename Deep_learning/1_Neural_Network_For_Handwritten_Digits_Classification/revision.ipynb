{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8c50de-9074-4295-a949-c3603878d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdd6094-ac0b-4769-b3af-13053412e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f388e311-0f40-4474-9dc7-7b26009a17d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df85b750-cab8-4285-8bfc-555c950e75ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d63199-0073-4327-8b88-13e0339ba3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1db1cd35730>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26221279-c051-4b57-8944-11a38ecc9e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d21355-4b72-4107-8770-4bbcb1316428",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5419739b-d0d5-43cf-969e-6398656bd33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train_flattened)\n",
    "scaled_X_test = scaler.fit_transform(X_test_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60ded321-6eb7-4f7e-b8ed-cc0fa0fb6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10,input_shape =(784,),activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb1a5fa2-9ae8-4dc6-901c-9c5841d00e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d5d0b93-11d1-425e-b46e-8ac852e04cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8956 - loss: 5.0528\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8914 - loss: 5.1466\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8956 - loss: 4.7786\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8913 - loss: 4.9308\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8929 - loss: 4.9499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1db57ba41a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5068142c-0233-4e43-9f09-b489342208a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75bb4024-49cf-4367-8cf9-b8901d23983b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1851325e-06, 1.5244022e-04, 2.7063312e-05, 3.8930897e-03,\n",
       "       3.2488357e-12, 8.9220862e-08, 6.9327410e-10, 9.9999994e-01,\n",
       "       4.3827922e-06, 7.3613580e-03], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efb9fe2b-504d-45ce-b096-a2cfc9d97bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = [np.argmax(i) for i in y_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c86a197-2f15-4bc8-b1d5-9ca9e990413d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85a07f7f-11b4-4e43-813b-53146c9081b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[ 968,    1,    0,    2,    1,    2,    2,    1,    2,    1],\n",
       "       [   0, 1126,    2,    0,    0,    0,    2,    1,    4,    0],\n",
       "       [   1,    1, 1015,    4,    1,    0,    2,    4,    3,    1],\n",
       "       [   1,    0,    3,  991,    0,    4,    0,    5,    3,    3],\n",
       "       [   3,    1,    4,    0,  956,    0,    3,    4,    0,   11],\n",
       "       [   2,    0,    0,    3,    1,  882,    2,    0,    2,    0],\n",
       "       [   3,    2,    0,    1,    1,    2,  949,    0,    0,    0],\n",
       "       [   2,    1,    5,    1,    1,    0,    1, 1010,    3,    4],\n",
       "       [   5,    1,    2,    2,    1,    1,    4,    2,  950,    6],\n",
       "       [   2,    2,    0,    1,    9,    2,    3,    7,    6,  977]])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58119b58-1ec0-45d8-8743-ace82dcced0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9075 - loss: 0.3106\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9775 - loss: 0.0763\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9869 - loss: 0.0440\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0326\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9930 - loss: 0.0230\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 0.0167\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0183\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0106\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0095\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1db23c3c260>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1000, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(scaled_X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79bc48a8-552d-4397-a653-caa1f58514ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07397915422916412, 0.9824000000953674]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee8b3513-d3c3-4562-ba1a-617cb50576a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('revision_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031ae71-0062-40de-a552-ca250767dc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
